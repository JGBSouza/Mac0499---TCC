%!TeX root=../tese.tex
%("dica" para o editor de texto: este arquivo é parte de um documento maior)
% para saber mais: https://tex.stackexchange.com/q/78101

%% ------------------------------------------------------------------------- %%

% "\chapter" cria um capítulo com número e o coloca no sumário; "\chapter*"
% cria um capítulo sem número e não o coloca no sumário. A introdução não
% deve ser numerada, mas deve aparecer no sumário. Por conta disso, este
% modelo define o comando "\chapter**".
\chapter**{Introdução}
\label{cap:introducao}

Computadores são parte central da vida em sociedade, servindo como pilar das relações modernas. Um \textit{Sistema Operacional} (SO) é um conjunto de softwares que, de acordo com \citet{tanenbaum2023modern}, realiza duas funções principais: \textbf{abstração} e \textbf{gerenciamento} do hardware que compõe as máquinas. Isto possibilita a interação entre ser humano e computador, tanto para a sua programação quanto para o seu uso, de forma simplificada e eficiente. Em sua composição, os SOs são divididos em diversos componentes específicos, dentre os quais o \textit{kernel} (em português, \textit{núcleo}) é considerado a parte central. Este fato decorre principalmente das responsabilidades atribuídas a ele, que incluem a gestão da alocação de recursos entre programas em execução, o escalonamento de atividades críticas e o gerenciamento da comunicação entre periféricos (mouse, teclado, placas de vídeo dedicadas, entre outros) e o sistema. Absorver estas e inúmeras outras complexidades permite, por exemplo, que um simples programa colete input do usuário e o imprima na tela sem que o programador se preocupe em \textbf{como} o computador faz isto. Por baixo dos panos, o kernel processa ações do usuário por meio dos dispositivos de entrada, coordena o uso do processador, memória e outros recursos internos e, por fim, apresenta os resultados de forma significativa ao usuário, através dos dispositivos de saída. Nesta ilustração, se faz clara a responsabilidade do kernel de abstrair as especificidades de como realizar tais operações provendo uma \textit{interface de chamada de sistema} ao mesmo tempo que gerencia os recursos sendo usados \citep{silberschatz2018operating}.

Dentre as diversas implementações de kernel existentes, o Linux, criado por Linus Torvalds e lançado em 1991, destaca-se como um dos mais relevantes. Mesmo que não advogando explicitamente pelo movimento de software livre, Torvalds começou o projeto Linux como uma alternativa à hegemonia dos SOs proprietários \citep{torvalds1991release,torvalds1991announcement}, como o Unix, sendo construído de forma colaborativa por uma comunidade de desenvolvedores e disponibilizando livre acesso ao seu código e documentação. O kernel Linux é atualmente o maior projeto de software livre do mundo, utilizado por grandes empresas de tecnologia e computação, com incontáveis SOs que o usam como kernel (as chamadas \textbf{distribuições Linux}), rodando em, pelo menos, aproximadamente 58\%~\footnote{31\% constam como SOs desconhecidos e acredita-se que boa parte destes sejam Linux. Fonte: \url{https://w3techs.com/technologies/details/os-unix}; acessado em 9 de dezembro de 2025.} de todos os servidores web. Do ponto de vista de engenharia de software, após mais de três décadas desde seu lançamento, o projeto vem tendo um aumento no número de contribuições e pessoas envolvidas em cada ciclo de desenvolvimento das versões \textit{stable kernels} \citep{passos2025duksvissoft}, sem considerar outros esforços como desenvolvimento \textit{downstream}.

Para sustentar esse ciclo contínuo de desenvolvimento, o kernel Linux adota um modelo rigoroso descrito por Feitelson~\citep{feit2012perpetual} como modelo de desenvolvimento perpétuo, no qual novas funcionalidades, correções e versões de produção são liberadas continuamente, ao mesmo tempo em que versões mais antigas permanecem em manutenção.
Esse modelo é estruturado em três etapas principais. A primeira, denominada janela de mesclagem (do inglês, merge window), corresponde ao período em que os patches dos subsistemas e drivers já testados e validados são enviados à mainline, sob supervisão de Linus Torvalds, para integração ao kernel principal. Na prática, os contribuidores enviam patches continuamente aos subsistemas de que participam (por exemplo, IIO ou AMD-GFX), independentemente da fase do ciclo de releases. Durante a merge window, esses patches previamente testados e acumulados são submetidos à mainline, dando início ao processo formal de integração.
A partir dessas integrações, é lançada uma versão inicial do novo kernel, denominada de -rc1, iniciando-se a segunda etapa, o período de estabilização, durante o qual apenas correções e melhorias incrementais são aceitas.

Por fim, ao atingir o nível de qualidade necessário, a versão final para este ciclo é oficialmente lançada, e uma equipe reduzida (conhecida como o \textit{stable team}) passa a atuar na manutenção contínua desta versão, liberando novas correções enquanto uma nova janela de mesclagem é aberta.

Fora do ciclo de releases, embora este ocorra de forma consecutiva e estruturada, os contribuidores enviam suas contribuições continuamente para os subsistemas específicos, como IIO, AMD-GFX e outros, testando e validando localmente seus patches. Mantenedores e a comunidade se encarregam de gerir essas contribuições, aplicando revisões e testes, garantindo a integração adequada com a mainline, e é neste contexto que o processo de revisão de código se torna mais significativo, mesmo que algumas interações diretas com Linus ou entre subsistemas ocorram em casos específicos.

Dentro desse fluxo contínuo de contribuição, os patches exigem um processo de preparação que envolve diversas etapas, como o design — em que são definidas as concepções iniciais e as implementações necessárias —, a revisão — em que as contribuições são avaliadas pela comunidade e pelos mantenedores —, e a fase de mesclagem e manutenção, em que o desenvolvedor continua responsável por eventuais ajustes após a integração. Considerando a complexidade inerente a um sistema operacional, desenvolver para o kernel Linux representa um desafio significativo para a maioria dos programadores, em razão do amplo conhecimento prático e teórico exigido.

Com o intuito de reduzir parte dessas dificuldades, a comunidade desenvolveu ferramentas destinadas à automação dos fluxos de trabalho. Entre elas, destaca-se o \textit{Kworkflow} (kw), uma ferramenta de software livre desenvolvida majoritariamente em Bash script, que tem como objetivo oferecer uma solução unificada para os diversos desafios enfrentados pelos desenvolvedores do kernel. Para isso, o kw integra e simplifica ferramentas e serviços amplamente consolidados na comunidade, como Git, o arquivo do Lore e o b4, criando soluções locais quando necessário. A ferramenta organiza-se como um hub de funcionalidades, recebendo comandos do usuário via linha de comando e redirecionando a execução para o módulo apropriado, de modo a oferecer uma interface única para todo o processo.

Apesar da ampla estrutura já existente, compreender de forma completa o fluxo de contribuição ao kernel continua sendo um desafio que o kw busca superar, permanecendo em constante desenvolvimento pela comunidade. Além de automatizar o workflow de desenvolvimento de patches, o kw tem o objetivo de se constituir como um software científico e, para isso, precisa ser capaz de fornecer rastreabilidade das contribuições, coletar dados do processo e possibilitar sua análise empírica, tornando possível que pesquisas, principalmente em Engenharia de Software, sejam desenvolvidas tendo como base a ferramenta.

Um dos processos ainda em aberto consiste em automatizar a gestão dos patches após a submissão e antes da aprovação, período em que as contribuições passam pela revisão dos mantenedores — uma etapa particularmente complexa no modelo de contribuição por listas de e-mail adotado pelo projeto Linux.

Um dos grandes desafios no desenvolvimento de sistemas de software é coordenar o trabalho simultâneo de diversos colaboradores, o que envolve a gestão de versões, submissões e atualizações. Antes do surgimento dos sistemas de controle de versão, esse processo era realizado manualmente, com métodos como cópias redundantes e convenções de nomenclatura, o que se mostrava inconsistente e de difícil manutenção. Com a introdução dos Version Control Systems (VCS), tornou-se possível registrar o histórico das alterações e recuperar versões anteriores. A evolução desses sistemas levou ao surgimento dos modelos distribuídos, como o Git, que permitiram maior flexibilidade e paralelismo, possibilitando que cada colaborador mantivesse uma cópia local do código e realizasse integrações controladas de suas modificações.

Mesmo assim, conforme aponta \citet{kernelrecipes}, ferramentas como GitHub e Gerrit, embora adequadas a projetos menores, ainda apresentam limitações quando aplicadas a softwares de grande escala, como o kernel Linux.
Entre os principais entraves estão o tempo elevado de revisão, a dificuldade de organização e categorização de problemas, a baixa acessibilidade das discussões internas e a sobrecarga das listas de pendências dos mantenedores. Parte dessas dificuldades é mitigada pelo uso de servidores de e-mail como meio principal de contribuição, que, embora resolvam alguns problemas de escalabilidade, introduzem outros desafios, como o alto custo de entrada para novos desenvolvedores, a rastreabilidade limitada das revisões, a sobrecarga das caixas de entrada, a possibilidade de corrupção de arquivos e a dificuldade de coletar métricas sobre o processo de desenvolvimento. Além disso, a necessidade de recorrer a ferramentas externas, como navegadores ou clientes de e-mail, fragmenta o fluxo de trabalho, afastando-se do princípio do kw de oferecer uma experiência integrada.

A dependência de sistemas de e-mail representa, portanto, uma limitação à proposta do kw de abranger o processo de desenvolvimento de forma holística. O usuário submete suas alterações por meio do kw, mas precisa recorrer a outros meios para acompanhar revisões e retornar à ferramenta para atualizar suas submissões, o que dificulta também a análise completa do fluxo de contribuição — um dos objetivos centrais do projeto.

Considerando esse cenário, este trabalho dá continuidade ao processo de melhoria contínua do kw, iniciado por iniciativas anteriores, como Simplificando o processo de contribuição para o kernel Linux \citep{gomes2022kernelworkflow} e Integrating the Kworkflow system with the Lore archives: Enhancing the Linux kernel developer interaction with mailing lists \citep{tadokoro2023kwlore}. A proposta aqui apresentada consiste em oferecer aprimoramentos e automatizações voltadas à gestão de patches durante o processo de revisão, integrando-se às implementações anteriores que introduzem, respectivamente, os fluxos de envio e de consulta de patches.

