%!TeX root=../tese.tex
%("dica" para o editor de texto: este arquivo é parte de um documento maior)
% para saber mais: https://tex.stackexchange.com/q/78101

%% ------------------------------------------------------------------------- %%

% "\chapter" cria um capítulo com número e o coloca no sumário; "\chapter*"
% cria um capítulo sem número e não o coloca no sumário. A introdução não
% deve ser numerada, mas deve aparecer no sumário. Por conta disso, este
% modelo define o comando "\chapter**".
\chapter**{Introdução}
\label{cap:introducao}

Computadores são parte central da vida em sociedade, servindo como pilar das relações modernas. Um \textit{Sistema Operacional} (SO) é um conjunto de softwares que, de acordo com \citet{tanenbaum2023modern}, realiza duas funções principais: \textbf{abstração} e \textbf{gerenciamento} do hardware que compõe as máquinas. Isto possibilita a interação entre ser humano e computador, tanto para a sua programação quanto para o seu uso, de forma simplificada e eficiente. Em sua composição, os SOs são divididos em diversos componentes específicos, dentre os quais o \textit{kernel} (em português, \textit{núcleo}) é considerado a parte central. Este fato decorre principalmente das responsabilidades atribuídas a ele, que incluem a gestão da alocação de recursos entre programas em execução, a priorização~\todo{veja se ``escalonamento'' não fica melhor} de atividades críticas e o gerenciamento da comunicação entre periféricos (mouse, teclado, placas de vídeo dedicadas, entre outros) e o sistema. Absorver estas e inúmeras outras complexidades permite, por exemplo, que um simples programa colete input do usuário e o imprima na tela sem que o programador se preocupe em \textbf{como} o computador faz isto. Por baixo dos panos, o kernel processa ações do usuário por meio dos dispositivos de entrada, coordena o uso do processador, memória e outros recursos internos e, por fim, apresenta os resultados de forma significativa ao usuário, através dos dispositivos de saída. Nesta ilustração, se faz clara a responsabilidade do kernel de abstrair as especificidades de como realizar tais operações provendo uma \textit{interface de chamada de sistema} ao mesmo tempo que gerencia os recursos sendo usados \citep{silberschatz2018operating}.

Dentre as diversas implementações de kernel existentes, o Linux, criado por Linus Torvalds e lançado em 1991, destaca-se como um dos mais relevantes. Mesmo que não advogando explicitamente pelo movimento de software livre, Torvalds começou o projeto Linux como uma alternativa à hegemonia dos SOs proprietários \citep{torvalds1991release,torvalds1991announcement}, como o Unix, sendo construído de forma colaborativa por uma comunidade de desenvolvedores e disponibilizando livre acesso ao seu código e documentação. O kernel Linux é atualmente o maior projeto de software livre do mundo, utilizado por grandes empresas de tecnologia e computação, com incontáveis SOs que o usam como kernel (as chamadas \textbf{distribuições Linux}), rodando em, pelo menos, aproximadamente 58\%~\footnote{31\% constam como SOs desconhecidos e acredita-se que boa parte destes sejam Linux. Fonte: \url{https://w3techs.com/technologies/details/os-unix}; acessado em 9 de dezembro de 2025.} de todos os servidores web. Do ponto de vista de engenharia de software, após mais de três décadas desde seu lançamento, o projeto vem tendo um aumento no número de contribuições e pessoas envolvidas em cada ciclo de desenvolvimento das versões \textit{stable kernels} \citep{passos2025duksvissoft}, sem considerar outros esforços como desenvolvimento \textit{downstream}.

Para sustentar esse ciclo contínuo de desenvolvimento, o kernel Linux adota um modelo rigoroso descrito por Feitelson~\citep{feit2012perpetual} como \textit{perpetual development}, no qual novas funcionalidades, correções e versões de produção são liberadas continuamente, ao mesmo tempo em que versões mais antigas permanecem em manutenção.\todo[inline]{O projeto Linux tem meio que ``dois ciclos'' de desenvolvimento em paralelo e é legal pontuar que eles existem e que você vai falar do ciclo de releases (no próximo TODO fica mais claro).}
Esse modelo é estruturado em três etapas principais. A primeira, denominada \textit{janela de mesclagem} (do inglês, \textit{merge window}), corresponde ao período em que as contribuições dos desenvolvedores são enviadas aos mantenedores — integrantes da comunidade responsáveis pela administração das submissões e pela verificação da conformidade com os padrões do projeto.\todo[inline]{Na verdade, patches dos contribuidores até os subsistemas/drivers mais baixo na hierarquia ocorrem de forma contínua, isto é, eu sempre posso mandar um patch pro IIO ou pra AMD-GFX, não importa qual fase do ciclo de release esteja. Merge window, as \texttt{-rc}s e o período de estabilização da release, ocorrem só entre subsistemas e a mainline (Linus); ou seja, o pessoal do IIO, AMD-GFX, etc., vai acumulando patches (e testando) pra próxima merge-window e, quando ela abre, eles enviam pro Linus uma enxurrada de patches que já estão testados e validados (supostamente, no contexto deles e na \texttt{-next}). Dê uma olhada neste material \url{https://www.kernel.org/doc/html/v6.17/process/2.Process.html}; acho que você referencia ele no capítulo 1, mas reveja, pois acho que está tendo uma confusão. Comento mais na frente, mas talvez a explicação detalhada caiba mais no capítulo 2 e aqui mais o overview que você mirou, porém corrigido.}
A partir dessas integrações, é lançada uma versão inicial do novo kernel, iniciando-se a segunda etapa, o período de estabilização, durante o qual apenas correções e melhorias incrementais são aceitas.\todo[inline]{Complementar ``versão inicial do novo kernel'' com algo como ``(denominada de -rc1, de \textit{release candidate})''. Novamente, no capítulo 2 entramos em detalhes (quantas rcs acontecem normalmente, um rc por semana, mais ou menos, etc.)}
Por fim, ao atingir o nível de qualidade necessário, a versão final para este ciclo é oficialmente lançada, e uma equipe reduzida (conhecida como o \textit{stable team}) passa a atuar na manutenção contínua desta versão, liberando novas correções enquanto uma nova janela de mesclagem é aberta.

Assim como o kernel, os patches incorporados durante a janela de mesclagem também exigem um processo de preparação que envolve diversas etapas, como o design — em que são definidas as concepções iniciais e as implementações necessárias —, a revisão — em que as contribuições são avaliadas pela comunidade e pelos mantenedores —, e a fase de mesclagem e manutenção, em que o desenvolvedor continua responsável por eventuais ajustes após a integração. Considerando a complexidade inerente a um sistema operacional, desenvolver para o kernel Linux representa um desafio significativo para a maioria dos programadores, em razão do amplo conhecimento prático e teórico exigido.\todo[inline]{- Não entendi bem o início ``Assim como o kernel''.

\hfill

- Gostei bastante da construção que você está fazendo pra sugir naturalmente a necessidade do kw e o workflow de desenvolvimento de patchset. No entanto, acho que como tem essa confusão da merge window, acho que este parágrafo pode ir na linha de (só uma ideia, então refine) ``Fora o ciclo de releases que ocorre consecutivamente, mas tem etapas muito bem definidas, contribuidores enviam contribuições, de fato, num regime de fluxo contínuo. Mantenedores e a comunidade se encarregam de gerir tais contribuições e aqui o processo de revisão de código ocorre mais significativamente (apesar de entre o Linus e os subsistemas haver casos) <aí você completa com o workflow de desenvolvimento de patchset e o resto do parágrafo>.''

\hfill

- No final, vale deixar mais claro esse conhecimento \textbf{prático}. Talvez na linha de a complexidadde inerente ser a parte teórica que já é difícil, fora todas essas outros detalhes práticos (técnicos e não-técnicos).}

Com o intuito de reduzir parte dessas dificuldades, a comunidade desenvolveu ferramentas destinadas à automação dos fluxos de trabalho. Entre elas, destaca-se o \textit{Kworkflow} (kw), uma ferramenta de software livre desenvolvida majoritariamente em Bash script, que tem como objetivo oferecer uma solução unificada para os diversos desafios enfrentados pelos desenvolvedores do kernel. Para isso, o kw integra e simplifica ferramentas e serviços amplamente consolidados na comunidade, como Git, o arquivo do Lore e o b4, criando soluções locais quando necessário. A ferramenta organiza-se como um hub, recebendo comandos do usuário via linha de comando e redirecionando a execução para o módulo apropriado, de modo a oferecer uma interface única para todo o processo.\todo[inline]{Considerar ``[...] um hub \ul{de funcionalidades}, [...]''}

Apesar da ampla estrutura já existente, compreender de forma completa o fluxo de contribuição ao kernel continua sendo um desafio que o kw busca superar, permanecendo em constante desenvolvimento pela comunidade.\todo[inline]{Aqui é legal fazer (sucintamente) aquele comentário que fiz pra Nina sobre o kw na sua apresentação de pôster: além de ser uma solução pro kernel dev real, é também um software para pesquisa que permite fazermos pesquisa (principalmente em Engenharia de Software) sobre o tópico.}
Um dos processos ainda em aberto consiste em automatizar a gestão dos patches após a submissão e antes da aprovação, período em que as contribuições passam pela revisão dos mantenedores — uma etapa particularmente complexa no modelo de contribuição por listas de e-mail adotado pelo projeto Linux.

Um dos grandes desafios no desenvolvimento de sistemas de software é coordenar o trabalho simultâneo de diversos colaboradores, o que envolve a gestão de versões, submissões e atualizações. Antes do surgimento dos sistemas de controle de versão, esse processo era realizado manualmente, com métodos como cópias redundantes e convenções de nomenclatura, o que se mostrava inconsistente e de difícil manutenção. Com a introdução dos Version Control Systems (VCS), tornou-se possível registrar o histórico das alterações e recuperar versões anteriores. A evolução desses sistemas levou ao surgimento dos modelos distribuídos, como o Git, que permitiram maior flexibilidade e paralelismo, possibilitando que cada colaborador mantivesse uma cópia local do código e realizasse integrações controladas de suas modificações.

Mesmo assim, conforme aponta Greg Kroah-Hartman (2016), ferramentas como GitHub e Gerrit, embora adequadas a projetos menores, ainda apresentam limitações quando aplicadas a softwares de grande escala, como o kernel Linux.\todo[inline]{Esses slides do Greg KH do Patches Carved into Stones (senão estiver confundindo) servem sim como referência, então não esqueça de colocá-lo. Ele deve entrar como um misc ou online no bibtex.}
Entre os principais entraves estão o tempo elevado de revisão, a dificuldade de organização e categorização de problemas, a baixa acessibilidade das discussões internas e a sobrecarga das listas de pendências dos mantenedores. Parte dessas dificuldades é mitigada pelo uso de servidores de e-mail como meio principal de contribuição, que, embora resolvam alguns problemas de escalabilidade, introduzem outros desafios, como o alto custo de entrada para novos desenvolvedores, a rastreabilidade limitada das revisões, a sobrecarga das caixas de entrada, a possibilidade de corrupção de arquivos e a dificuldade de coletar métricas sobre o processo de desenvolvimento. Além disso, a necessidade de recorrer a ferramentas externas, como navegadores ou clientes de e-mail, fragmenta o fluxo de trabalho, afastando-se do princípio do kw de oferecer uma experiência integrada.\todo{Muito bom!}

A dependência de sistemas de e-mail representa, portanto, uma limitação à proposta do kw de abranger o processo de desenvolvimento de forma holística. O usuário submete suas alterações por meio do kw, mas precisa recorrer a outros meios para acompanhar revisões e retornar à ferramenta para atualizar suas submissões, o que dificulta também a análise completa do fluxo de contribuição — um dos objetivos centrais do projeto.\todo[inline]{Dê mais um callback aqui sobre o kw ser software pra pesquisa que permite a gente entender esse ``zoológico'' que é o desenvolvimento Linux de uma forma mais empírica. No seu caso, é focado no workflow de desenvolvimento de patchset, mas aqui o argumento tem que ser que você está preenchendo um lacuna que habilitará outros pesquisadores a entenderem melhor o fenômeno Linux de forma \textbf{próxima da prática}.}

Considerando esse cenário, este trabalho dá continuidade ao processo de melhoria contínua do kw, iniciado por iniciativas anteriores, como Simplificando o processo de contribuição para o kernel Linux (Neto, 2022) e Integrating the KWorkflow system with the Lore archives: Enhancing the Linux kernel developer interaction with mailing lists (Barros Tadokoro, 2023). A proposta aqui apresentada consiste em oferecer aprimoramentos e automatizações voltadas à gestão de patches durante o processo de revisão, integrando-se às implementações anteriores que introduzem, respectivamente, os fluxos de envio e de consulta de patches.\todo[inline]{Use referências de fato aos nossos TCCs. Obs.: Oficialmente o título do meu TCC tem ``KWorkflow'', mas use ``Kworkflow'' :)}

\todo[inline]{Vale colocar um parágrafo de outline aqui, ou seja, algo como ``O resto do texto está estruturado da seguinte forma: Capítulo \textbackslash ref\{rotulo-cap-de-fund\} trará a fundamen[...]''}

